{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import ResNet50, EfficientNetB0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a variable for the dataset of sample (directory number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full dataset size\n",
    "\n",
    "# CT = 326 \n",
    "# CXR = 557\n",
    "\n",
    "# test dataset size \n",
    "\n",
    "CT =  20 \n",
    "CXR = 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f\"{CT}_CT_{CXR}_CXR\"\n",
    "dataset_base_directory = f\"/home/masresha/dataset/all_dataset\"\n",
    "generated_data_directory = f\"/home/masresha/dataset/generatedfile/{CT}_CT_{CXR}_CXR_generated\"\n",
    "result_data_directory = f\"/home/masresha/dataset/resultfile/{CT}_CT_{CXR}_CXR_resultfile\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the base directory exists<br>\n",
    "Function to check if a directory exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_directory_exists(directory_path, create_if_missing=False):\n",
    "    if not os.path.exists(directory_path):\n",
    "        if create_if_missing:  # Create the directory if flagged\n",
    "            os.makedirs(directory_path)\n",
    "            print(f\"üìÅ Created directory: {directory_path}\")\n",
    "        else:  # Show error and exit if not allowed to create\n",
    "            print(f\"‚ùå ERROR: Directory does not exist: {directory_path}. Exiting...\")\n",
    "            sys.exit(1)  # Abort execution\n",
    "    else:\n",
    "        print(f\"‚úÖ Directory exists: {directory_path}\")\n",
    "        return directory_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensure_directory_exists(dataset_base_directory, create_if_missing=False)  # Must exist\n",
    "ensure_directory_exists(generated_data_directory, create_if_missing=True)  # Create if missing\n",
    "ensure_directory_exists(result_data_directory, create_if_missing=True)  # Create if missing\n",
    "print(\"All directory checks and setups are complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load fused features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(d_type, feature_model, training_type):\n",
    "    if training_type == 'fused_data':   \n",
    "        load_dir = os.path.join(generated_data_directory,training_type, d_type,feature_model)\n",
    "        ensure_directory_exists(load_dir)\n",
    "        X = np.load(ensure_directory_exists(os.path.join(load_dir, f\"{d_type}_{feature_model}_fused_features.npy\")))\n",
    "        y = np.load(ensure_directory_exists(os.path.join(load_dir, f\"{d_type}_{feature_model}_labels.npy\")))\n",
    "        return X, y\n",
    "    elif training_type == 'clinical_data_only':\n",
    "        data_dir = os.path.join(generated_data_directory,'selected_features_csv',d_type)\n",
    "        ensure_directory_exists(data_dir)\n",
    "        data = pd.read_csv(ensure_directory_exists(os.path.join(data_dir, f\"{d_type}_clinical_data_selected_features_{feature_model}.csv\")))\n",
    "        X = data.drop(columns=['label'])\n",
    "        y = data['label']\n",
    "        return X, y\n",
    "    elif training_type == 'image_data_only':\n",
    "        data_dir = os.path.join(generated_data_directory,'selected_features_image_npy',d_type)\n",
    "        ensure_directory_exists(data_dir)\n",
    "        X = np.load(ensure_directory_exists(os.path.join(data_dir, f\"{d_type}_image_features.npy\")))\n",
    "        y = np.load(ensure_directory_exists(os.path.join(data_dir, f\"{d_type}_image_labels.npy\")))\n",
    "        return X, y\n",
    "    elif training_type == 'CNN':\n",
    "        data_dir = os.path.join(generated_data_directory, 'merged_preprocessed_image_npy',d_type)\n",
    "        ensure_directory_exists(data_dir)\n",
    "        X = np.load(ensure_directory_exists(os.path.join(data_dir, f\"{d_type}_image_data.npy\")))\n",
    "        y = np.load(ensure_directory_exists(os.path.join(data_dir, f\"{d_type}_image_labels.npy\")))\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(d_type, model_name, model, feature_model, training_type, save_type='plk'):\n",
    "    # Create 'saved_models' subfolder if it doesn't exist\n",
    "    model_dir = os.path.join(result_data_directory, training_type, 'saved_models',d_type)\n",
    "    ensure_directory_exists(model_dir, create_if_missing=True)\n",
    "\n",
    "    # Save model in 'saved_models' subfolder\n",
    "    if save_type == 'pkl':\n",
    "        joblib.dump(model, os.path.join(model_dir,f\"{d_type}_{training_type}_{feature_model}_{model_name}_model_sample_size_{d_type}.pkl\"))\n",
    "        print(f\"Model training and evaluation complete. Model saved as '{d_type}_{training_type}_{feature_model}_{model_name}_model_sample_size_{d_type}.pkl'\")\n",
    "    elif save_type == 'keras':\n",
    "        model.save(os.path.join(model_dir, f\"{d_type}_{training_type}_{feature_model}_{model_name}_model_sample_size_{d_type}.keras\"))   \n",
    "        print(f\"Model training and evaluation complete. Model saved as '{d_type}_{training_type}_{feature_model}_{model_name}_model_sample_size_{d_type}.keras'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_evaluation_result(d_type, y_true, y_pred, model_name, feature_model, inference_time_train, inference_time, evaluation_type, params, training_type):\n",
    "    if evaluation_type != 'Eval_Test':\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        report = classification_report(y_true, y_pred, digits=6)\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        print(f\"[{d_type}] [{feature_model}] [{training_type}] {model_name} {evaluation_type} Results (Sample size = {dataset}):\")\n",
    "        print(f\"[{d_type}] [{feature_model}] [{training_type}] {evaluation_type} Accuracy:\", acc)\n",
    "        print(f\"[{d_type}] [{feature_model}] [{training_type}] {evaluation_type} inference_time_train:\", inference_time_train)\n",
    "        print(f\"[{d_type}] [{feature_model}] [{training_type}] {evaluation_type} inference_time_{evaluation_type}:\", inference_time)\n",
    "        print(f\"{model_name} parameters: \\n {str(params)}\")\n",
    "        print(f\"[{d_type}] [{feature_model}] {evaluation_type} Classification Report:\", report, '\\n')\n",
    "\n",
    "        # Write results to a text file\n",
    "        txt_dir = os.path.join(result_data_directory, training_type,'evaluation_result',d_type)\n",
    "        ensure_directory_exists(txt_dir, create_if_missing=True)\n",
    "        result_file = os.path.join(txt_dir, f\"{d_type}_{feature_model}_evaluation_results_{dataset}.txt\")\n",
    "        with open(result_file, \"a\") as file:\n",
    "            file.write(f\"\\n========================\\n[{d_type}]  [{training_type}] [{feature_model}] {model_name} {evaluation_type} Results (Sample size = {dataset}):\\n\")\n",
    "            file.write(f\"[{model_name}{d_type}] {evaluation_type} parameters: {str(params)}\\n\")\n",
    "            file.write(f\"[{d_type}] [{training_type}] {evaluation_type} Accuracy: {acc}\\n\")\n",
    "            file.write(f\"[{d_type}] [{training_type}] {evaluation_type} inference_time_train: {inference_time_train}\\n\")\n",
    "            file.write(f\"[{d_type}] [{training_type}] {evaluation_type} inference_time_{evaluation_type}: {inference_time}\\n\")\n",
    "            file.write(f\"[{d_type}] [{training_type}] {evaluation_type} Classification Report: \\n{report}\\n\")\n",
    "            file.write(f\"[{d_type}] [{training_type}] {evaluation_type} Confusion Matrix:\\n\")\n",
    "            cm_df = pd.DataFrame(cm)  # Create a pandas DataFrame\n",
    "            file.write(cm_df.to_string())  # Convert the DataFrame to a string\n",
    "            file.write(\"\\n\")\n",
    "        print(f\"[{d_type}]  [{training_type}] [{feature_model}] {model_name} {evaluation_type} results saved to {result_file}\")\n",
    "\n",
    "        # Plot confusion matrix\n",
    "        plt.figure()\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title(f'[{d_type}] [{feature_model}] [{training_type}] {model_name} {evaluation_type} \\nConfusion Matrix (Sample size = {dataset})')\n",
    "\n",
    "        # Save confusion matrix\n",
    "        plt.tight_layout()\n",
    "        confusion_matrix_dir = os.path.join(result_data_directory, training_type,'evaluation_result',d_type,f'{d_type}_{feature_model}_confusion_matrix')\n",
    "        ensure_directory_exists(confusion_matrix_dir, True)\n",
    "        confusion_matrix_file = os.path.join(confusion_matrix_dir, f\"{d_type}_{feature_model}_{model_name}_{evaluation_type}_confusion_matrix_sample_size_{dataset}.png\")\n",
    "        plt.savefig(confusion_matrix_file)\n",
    "        plt.close()\n",
    "        print(f\"[{d_type}] [{feature_model}] {model_name} {training_type} {evaluation_type} \\nConfusion matrix saved to {confusion_matrix_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(history, d_type, feature_model, model_name, training_type, dataset, graph_type):\n",
    "    \"\"\"\n",
    "    Plots and saves training/validation accuracy and loss graphs.\n",
    "    \n",
    "    Parameters:\n",
    "    - history: Training history containing 'accuracy', 'val_accuracy', 'loss', and 'val_loss'\n",
    "    - d_type: Dataset type for the plot title and file name\n",
    "    - feature_model: Feature extraction model used in training\n",
    "    - model_name: Name of the model being evaluated\n",
    "    - training_type: Type of training used (e.g., 'fine-tuning', 'transfer')\n",
    "    - dataset: Dataset used for training\n",
    "    - graph_type: Type of graph to plot ('accuracy' or 'loss')\n",
    "    \"\"\"\n",
    "    if graph_type == 'accuracy':\n",
    "        metric = 'accuracy'\n",
    "        val_metric = 'val_accuracy'\n",
    "        title = f'[{d_type}]Training and validation accuracy of model: {model_name}, \\nFeature extraction: {feature_model}, dataset type: {training_type}'\n",
    "    elif graph_type == 'loss':\n",
    "        metric = 'loss'\n",
    "        val_metric = 'val_loss'\n",
    "        title = f'[{d_type}]Training and validation loss of model: {model_name}, \\nFeature extraction: {feature_model}, dataset type: {training_type}'\n",
    "    else:\n",
    "        raise ValueError(\"graph_type should be either 'accuracy' or 'loss'\")\n",
    "    \n",
    "    # Extract data from history\n",
    "    metric_data = history.history[metric]\n",
    "    val_metric_data = history.history[val_metric]\n",
    "    \n",
    "    epochs = range(1, len(metric_data) + 1)\n",
    "\n",
    "    # Plot the graph\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, metric_data, label=f'Training {graph_type}')\n",
    "    plt.plot(epochs, val_metric_data, label=f'Validation {graph_type}')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "\n",
    "    # Save the plot\n",
    "    plt.tight_layout()\n",
    "    training_plots_dir = os.path.join(result_data_directory, training_type, 'evaluation_result', d_type, f'{d_type}_{feature_model}_training_plots')\n",
    "    ensure_directory_exists(training_plots_dir, True)\n",
    "    plot_file = os.path.join(training_plots_dir, f\"{d_type}_{feature_model}_{model_name}_{graph_type}_training_plots_sample_size_{dataset}.png\")\n",
    "    plt.savefig(plot_file)\n",
    "    print(f\"[{d_type}] [{feature_model}] {model_name} {training_type} '{graph_type}' training plots saved to {plot_file}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_deep_learning_model(input_dim, output_dim):\n",
    "    # a fully connected (dense) neural network\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_dim=input_dim),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(output_dim, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_resnet50_model(input_shape, output_dim):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    base_model.trainable = False  # Freeze the base model\n",
    "\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(output_dim, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_efficientnetb0_model(input_shape, output_dim):\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    base_model.trainable = False  # Freeze the base model\n",
    "\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(output_dim, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop with validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëâüëâüëâüëâ  CT  üëàüëàüëàüëà\n",
      "‚è© Working on: fused_data mi training\n",
      "‚úÖ Directory exists: /home/masresha/dataset/generatedfile/20_CT_20_CXR_generated/fused_data/CT/mi\n",
      "‚úÖ Directory exists: /home/masresha/dataset/generatedfile/20_CT_20_CXR_generated/fused_data/CT/mi/CT_mi_fused_features.npy\n",
      "‚úÖ Directory exists: /home/masresha/dataset/generatedfile/20_CT_20_CXR_generated/fused_data/CT/mi/CT_mi_labels.npy\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 1s 15ms/step - loss: 3.2515 - accuracy: 0.6016 - val_loss: 2.0385 - val_accuracy: 0.8750\n",
      "Epoch 2/5\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 2.9464 - accuracy: 0.8750 - val_loss: 1.9062 - val_accuracy: 0.8750\n",
      "Epoch 3/5\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 2.1657 - accuracy: 0.8672 - val_loss: 4.9377 - val_accuracy: 0.8750\n",
      "Epoch 4/5\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 1.9112 - accuracy: 0.8906 - val_loss: 4.2594 - val_accuracy: 0.8750\n",
      "Epoch 5/5\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 2.6978 - accuracy: 0.8672 - val_loss: 1.9830 - val_accuracy: 0.8750\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "[CT] [mi] [fused_data] Fully_Connected Validation Results (Sample size = 20_CT_20_CXR):\n",
      "[CT] [mi] [fused_data] Validation Accuracy: 0.875\n",
      "[CT] [mi] [fused_data] Validation inference_time_train: 2.935774087905884\n",
      "[CT] [mi] [fused_data] Validation inference_time_Validation: 0.08154010772705078\n",
      "Fully_Connected parameters: \n",
      " Fully_Connected\n",
      "[CT] [mi] Validation Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0   0.500000  0.500000  0.500000         2\n",
      "           1   1.000000  1.000000  1.000000         2\n",
      "           2   1.000000  1.000000  1.000000         2\n",
      "           3   1.000000  0.500000  0.666667         2\n",
      "           4   1.000000  1.000000  1.000000         2\n",
      "           5   0.666667  1.000000  0.800000         2\n",
      "           6   1.000000  1.000000  1.000000         2\n",
      "           7   1.000000  1.000000  1.000000         2\n",
      "\n",
      "    accuracy                       0.875000        16\n",
      "   macro avg   0.895833  0.875000  0.870833        16\n",
      "weighted avg   0.895833  0.875000  0.870833        16\n",
      " \n",
      "\n",
      "‚úÖ Directory exists: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CT\n",
      "[CT]  [fused_data] [mi] Fully_Connected Validation results saved to /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CT/CT_mi_evaluation_results_20_CT_20_CXR.txt\n",
      "‚úÖ Directory exists: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CT/CT_mi_confusion_matrix\n",
      "[CT] [mi] Fully_Connected fused_data Validation \n",
      "Confusion matrix saved to /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CT/CT_mi_confusion_matrix/CT_mi_Fully_Connected_Validation_confusion_matrix_sample_size_20_CT_20_CXR.png\n",
      "‚úÖ Directory exists: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/saved_models/CT\n",
      "Model training and evaluation complete. Model saved as 'CT_fused_data_mi_Fully_Connected_model_sample_size_CT.keras'\n",
      "‚úÖ Directory exists: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CT/CT_mi_training_plots\n",
      "[CT] [mi] Fully_Connected fused_data 'accuracy' training plots saved to /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CT/CT_mi_training_plots/CT_mi_Fully_Connected_accuracy_training_plots_sample_size_20_CT_20_CXR.png\n",
      "‚úÖ Directory exists: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CT/CT_mi_training_plots\n",
      "[CT] [mi] Fully_Connected fused_data 'loss' training plots saved to /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CT/CT_mi_training_plots/CT_mi_Fully_Connected_loss_training_plots_sample_size_20_CT_20_CXR.png\n",
      "‚è© Working on: fused_data rf training\n",
      "‚úÖ Directory exists: /home/masresha/dataset/generatedfile/20_CT_20_CXR_generated/fused_data/CT/rf\n",
      "‚úÖ Directory exists: /home/masresha/dataset/generatedfile/20_CT_20_CXR_generated/fused_data/CT/rf/CT_rf_fused_features.npy\n",
      "‚úÖ Directory exists: /home/masresha/dataset/generatedfile/20_CT_20_CXR_generated/fused_data/CT/rf/CT_rf_labels.npy\n",
      "Epoch 1/5\n",
      "43/43 [==============================] - 1s 12ms/step - loss: 6.4282 - accuracy: 0.5703 - val_loss: 3.6693 - val_accuracy: 0.8750\n",
      "Epoch 2/5\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 2.9757 - accuracy: 0.8359 - val_loss: 3.2244 - val_accuracy: 0.8750\n",
      "Epoch 3/5\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 2.5276 - accuracy: 0.8984 - val_loss: 1.3840 - val_accuracy: 0.8750\n",
      "Epoch 4/5\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 1.7215 - accuracy: 0.8984 - val_loss: 0.0251 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 1.4497 - accuracy: 0.9219 - val_loss: 3.0595 - val_accuracy: 0.8125\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "[CT] [rf] [fused_data] Fully_Connected Validation Results (Sample size = 20_CT_20_CXR):\n",
      "[CT] [rf] [fused_data] Validation Accuracy: 0.8125\n",
      "[CT] [rf] [fused_data] Validation inference_time_train: 2.7346198558807373\n",
      "[CT] [rf] [fused_data] Validation inference_time_Validation: 0.08334803581237793\n",
      "Fully_Connected parameters: \n",
      " Fully_Connected\n",
      "[CT] [rf] Validation Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0   0.500000  0.500000  0.500000         2\n",
      "           1   1.000000  0.500000  0.666667         2\n",
      "           2   1.000000  1.000000  1.000000         2\n",
      "           3   0.500000  0.500000  0.500000         2\n",
      "           4   1.000000  1.000000  1.000000         2\n",
      "           5   0.666667  1.000000  0.800000         2\n",
      "           6   1.000000  1.000000  1.000000         2\n",
      "           7   1.000000  1.000000  1.000000         2\n",
      "\n",
      "    accuracy                       0.812500        16\n",
      "   macro avg   0.833333  0.812500  0.808333        16\n",
      "weighted avg   0.833333  0.812500  0.808333        16\n",
      " \n",
      "\n",
      "‚úÖ Directory exists: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CT\n",
      "[CT]  [fused_data] [rf] Fully_Connected Validation results saved to /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CT/CT_rf_evaluation_results_20_CT_20_CXR.txt\n",
      "‚úÖ Directory exists: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CT/CT_rf_confusion_matrix\n",
      "[CT] [rf] Fully_Connected fused_data Validation \n",
      "Confusion matrix saved to /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CT/CT_rf_confusion_matrix/CT_rf_Fully_Connected_Validation_confusion_matrix_sample_size_20_CT_20_CXR.png\n",
      "‚úÖ Directory exists: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/saved_models/CT\n",
      "Model training and evaluation complete. Model saved as 'CT_fused_data_rf_Fully_Connected_model_sample_size_CT.keras'\n",
      "‚úÖ Directory exists: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CT/CT_rf_training_plots\n",
      "[CT] [rf] Fully_Connected fused_data 'accuracy' training plots saved to /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CT/CT_rf_training_plots/CT_rf_Fully_Connected_accuracy_training_plots_sample_size_20_CT_20_CXR.png\n",
      "‚úÖ Directory exists: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CT/CT_rf_training_plots\n",
      "[CT] [rf] Fully_Connected fused_data 'loss' training plots saved to /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CT/CT_rf_training_plots/CT_rf_Fully_Connected_loss_training_plots_sample_size_20_CT_20_CXR.png\n",
      "‚è© Working on: fused_data pca training\n",
      "‚úÖ Directory exists: /home/masresha/dataset/generatedfile/20_CT_20_CXR_generated/fused_data/CT/pca\n",
      "‚úÖ Directory exists: /home/masresha/dataset/generatedfile/20_CT_20_CXR_generated/fused_data/CT/pca/CT_pca_fused_features.npy\n",
      "‚úÖ Directory exists: /home/masresha/dataset/generatedfile/20_CT_20_CXR_generated/fused_data/CT/pca/CT_pca_labels.npy\n",
      "Epoch 1/5\n",
      "43/43 [==============================] - 1s 13ms/step - loss: 5.3599 - accuracy: 0.5859 - val_loss: 4.5867 - val_accuracy: 0.8750\n",
      "Epoch 2/5\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 2.9024 - accuracy: 0.8438 - val_loss: 5.7108 - val_accuracy: 0.8125\n",
      "Epoch 3/5\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 2.3846 - accuracy: 0.8750 - val_loss: 1.8058 - val_accuracy: 0.8750\n",
      "Epoch 4/5\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 1.9405 - accuracy: 0.9062 - val_loss: 2.2182 - val_accuracy: 0.8750\n",
      "Epoch 5/5\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 1.7299 - accuracy: 0.9219 - val_loss: 2.2657 - val_accuracy: 0.8750\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "[CT] [pca] [fused_data] Fully_Connected Validation Results (Sample size = 20_CT_20_CXR):\n",
      "[CT] [pca] [fused_data] Validation Accuracy: 0.875\n",
      "[CT] [pca] [fused_data] Validation inference_time_train: 2.73606276512146\n",
      "[CT] [pca] [fused_data] Validation inference_time_Validation: 0.07735848426818848\n",
      "Fully_Connected parameters: \n",
      " Fully_Connected\n",
      "[CT] [pca] Validation Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0   0.500000  1.000000  0.666667         2\n",
      "           1   1.000000  0.500000  0.666667         2\n",
      "           2   1.000000  1.000000  1.000000         2\n",
      "           3   1.000000  0.500000  0.666667         2\n",
      "           4   1.000000  1.000000  1.000000         2\n",
      "           5   1.000000  1.000000  1.000000         2\n",
      "           6   1.000000  1.000000  1.000000         2\n",
      "           7   1.000000  1.000000  1.000000         2\n",
      "\n",
      "    accuracy                       0.875000        16\n",
      "   macro avg   0.937500  0.875000  0.875000        16\n",
      "weighted avg   0.937500  0.875000  0.875000        16\n",
      " \n",
      "\n",
      "üìÅ Created directory: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CT\n",
      "[CT]  [fused_data] [pca] Fully_Connected Validation results saved to /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CT/CT_pca_evaluation_results_20_CT_20_CXR.txt\n",
      "üìÅ Created directory: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CT/CT_pca_confusion_matrix\n",
      "[CT] [pca] Fully_Connected fused_data Validation \n",
      "Confusion matrix saved to /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CT/CT_pca_confusion_matrix/CT_pca_Fully_Connected_Validation_confusion_matrix_sample_size_20_CT_20_CXR.png\n",
      "üìÅ Created directory: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/saved_models/CT\n",
      "Model training and evaluation complete. Model saved as 'CT_fused_data_pca_Fully_Connected_model_sample_size_CT.keras'\n",
      "üìÅ Created directory: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CT/CT_pca_training_plots\n",
      "[CT] [pca] Fully_Connected fused_data 'accuracy' training plots saved to /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CT/CT_pca_training_plots/CT_pca_Fully_Connected_accuracy_training_plots_sample_size_20_CT_20_CXR.png\n",
      "‚úÖ Directory exists: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CT/CT_pca_training_plots\n",
      "[CT] [pca] Fully_Connected fused_data 'loss' training plots saved to /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CT/CT_pca_training_plots/CT_pca_Fully_Connected_loss_training_plots_sample_size_20_CT_20_CXR.png\n",
      "üëâüëâüëâüëâ  CXR  üëàüëàüëàüëà\n",
      "‚è© Working on: fused_data mi training\n",
      "‚úÖ Directory exists: /home/masresha/dataset/generatedfile/20_CT_20_CXR_generated/fused_data/CXR/mi\n",
      "‚úÖ Directory exists: /home/masresha/dataset/generatedfile/20_CT_20_CXR_generated/fused_data/CXR/mi/CXR_mi_fused_features.npy\n",
      "‚úÖ Directory exists: /home/masresha/dataset/generatedfile/20_CT_20_CXR_generated/fused_data/CXR/mi/CXR_mi_labels.npy\n",
      "Epoch 1/5\n",
      "43/43 [==============================] - 1s 13ms/step - loss: 9.4984 - accuracy: 0.3750 - val_loss: 6.0903 - val_accuracy: 0.3750\n",
      "Epoch 2/5\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 4.8885 - accuracy: 0.5938 - val_loss: 3.9897 - val_accuracy: 0.6250\n",
      "Epoch 3/5\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 3.6141 - accuracy: 0.7266 - val_loss: 2.6624 - val_accuracy: 0.6875\n",
      "Epoch 4/5\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 2.3080 - accuracy: 0.7578 - val_loss: 3.2685 - val_accuracy: 0.6250\n",
      "Epoch 5/5\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 1.6184 - accuracy: 0.8125 - val_loss: 4.0968 - val_accuracy: 0.5625\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "[CXR] [mi] [fused_data] Fully_Connected Validation Results (Sample size = 20_CT_20_CXR):\n",
      "[CXR] [mi] [fused_data] Validation Accuracy: 0.5625\n",
      "[CXR] [mi] [fused_data] Validation inference_time_train: 2.7831075191497803\n",
      "[CXR] [mi] [fused_data] Validation inference_time_Validation: 0.07866930961608887\n",
      "Fully_Connected parameters: \n",
      " Fully_Connected\n",
      "[CXR] [mi] Validation Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0   0.000000  0.000000  0.000000         2\n",
      "           1   0.200000  0.500000  0.285714         2\n",
      "           2   0.000000  0.000000  0.000000         2\n",
      "           3   1.000000  1.000000  1.000000         2\n",
      "           4   0.500000  0.500000  0.500000         2\n",
      "           5   0.500000  1.000000  0.666667         2\n",
      "           6   1.000000  1.000000  1.000000         2\n",
      "           7   1.000000  0.500000  0.666667         2\n",
      "\n",
      "    accuracy                       0.562500        16\n",
      "   macro avg   0.525000  0.562500  0.514881        16\n",
      "weighted avg   0.525000  0.562500  0.514881        16\n",
      " \n",
      "\n",
      "üìÅ Created directory: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CXR\n",
      "[CXR]  [fused_data] [mi] Fully_Connected Validation results saved to /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CXR/CXR_mi_evaluation_results_20_CT_20_CXR.txt\n",
      "üìÅ Created directory: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CXR/CXR_mi_confusion_matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/masresha/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/masresha/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/masresha/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CXR] [mi] Fully_Connected fused_data Validation \n",
      "Confusion matrix saved to /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CXR/CXR_mi_confusion_matrix/CXR_mi_Fully_Connected_Validation_confusion_matrix_sample_size_20_CT_20_CXR.png\n",
      "üìÅ Created directory: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/saved_models/CXR\n",
      "Model training and evaluation complete. Model saved as 'CXR_fused_data_mi_Fully_Connected_model_sample_size_CXR.keras'\n",
      "üìÅ Created directory: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CXR/CXR_mi_training_plots\n",
      "[CXR] [mi] Fully_Connected fused_data 'accuracy' training plots saved to /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CXR/CXR_mi_training_plots/CXR_mi_Fully_Connected_accuracy_training_plots_sample_size_20_CT_20_CXR.png\n",
      "‚úÖ Directory exists: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CXR/CXR_mi_training_plots\n",
      "[CXR] [mi] Fully_Connected fused_data 'loss' training plots saved to /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CXR/CXR_mi_training_plots/CXR_mi_Fully_Connected_loss_training_plots_sample_size_20_CT_20_CXR.png\n",
      "‚è© Working on: fused_data rf training\n",
      "‚úÖ Directory exists: /home/masresha/dataset/generatedfile/20_CT_20_CXR_generated/fused_data/CXR/rf\n",
      "‚úÖ Directory exists: /home/masresha/dataset/generatedfile/20_CT_20_CXR_generated/fused_data/CXR/rf/CXR_rf_fused_features.npy\n",
      "‚úÖ Directory exists: /home/masresha/dataset/generatedfile/20_CT_20_CXR_generated/fused_data/CXR/rf/CXR_rf_labels.npy\n",
      "Epoch 1/5\n",
      "43/43 [==============================] - 1s 13ms/step - loss: 8.5359 - accuracy: 0.4062 - val_loss: 5.8560 - val_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 5.9244 - accuracy: 0.5703 - val_loss: 4.1021 - val_accuracy: 0.8125\n",
      "Epoch 3/5\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 4.2300 - accuracy: 0.7578 - val_loss: 5.5420 - val_accuracy: 0.6875\n",
      "Epoch 4/5\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 2.6363 - accuracy: 0.7578 - val_loss: 7.7445 - val_accuracy: 0.6250\n",
      "Epoch 5/5\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 2.1984 - accuracy: 0.7891 - val_loss: 9.5681 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "[CXR] [rf] [fused_data] Fully_Connected Validation Results (Sample size = 20_CT_20_CXR):\n",
      "[CXR] [rf] [fused_data] Validation Accuracy: 0.75\n",
      "[CXR] [rf] [fused_data] Validation inference_time_train: 2.9403204917907715\n",
      "[CXR] [rf] [fused_data] Validation inference_time_Validation: 0.08776354789733887\n",
      "Fully_Connected parameters: \n",
      " Fully_Connected\n",
      "[CXR] [rf] Validation Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0   1.000000  0.500000  0.666667         2\n",
      "           1   0.500000  0.500000  0.500000         2\n",
      "           2   0.500000  1.000000  0.666667         2\n",
      "           3   1.000000  1.000000  1.000000         2\n",
      "           4   1.000000  0.500000  0.666667         2\n",
      "           5   0.666667  1.000000  0.800000         2\n",
      "           6   1.000000  1.000000  1.000000         2\n",
      "           7   1.000000  0.500000  0.666667         2\n",
      "\n",
      "    accuracy                       0.750000        16\n",
      "   macro avg   0.833333  0.750000  0.745833        16\n",
      "weighted avg   0.833333  0.750000  0.745833        16\n",
      " \n",
      "\n",
      "‚úÖ Directory exists: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CXR\n",
      "[CXR]  [fused_data] [rf] Fully_Connected Validation results saved to /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CXR/CXR_rf_evaluation_results_20_CT_20_CXR.txt\n",
      "üìÅ Created directory: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CXR/CXR_rf_confusion_matrix\n",
      "[CXR] [rf] Fully_Connected fused_data Validation \n",
      "Confusion matrix saved to /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CXR/CXR_rf_confusion_matrix/CXR_rf_Fully_Connected_Validation_confusion_matrix_sample_size_20_CT_20_CXR.png\n",
      "‚úÖ Directory exists: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/saved_models/CXR\n",
      "Model training and evaluation complete. Model saved as 'CXR_fused_data_rf_Fully_Connected_model_sample_size_CXR.keras'\n",
      "üìÅ Created directory: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CXR/CXR_rf_training_plots\n",
      "[CXR] [rf] Fully_Connected fused_data 'accuracy' training plots saved to /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CXR/CXR_rf_training_plots/CXR_rf_Fully_Connected_accuracy_training_plots_sample_size_20_CT_20_CXR.png\n",
      "‚úÖ Directory exists: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CXR/CXR_rf_training_plots\n",
      "[CXR] [rf] Fully_Connected fused_data 'loss' training plots saved to /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CXR/CXR_rf_training_plots/CXR_rf_Fully_Connected_loss_training_plots_sample_size_20_CT_20_CXR.png\n",
      "‚è© Working on: fused_data pca training\n",
      "‚úÖ Directory exists: /home/masresha/dataset/generatedfile/20_CT_20_CXR_generated/fused_data/CXR/pca\n",
      "‚úÖ Directory exists: /home/masresha/dataset/generatedfile/20_CT_20_CXR_generated/fused_data/CXR/pca/CXR_pca_fused_features.npy\n",
      "‚úÖ Directory exists: /home/masresha/dataset/generatedfile/20_CT_20_CXR_generated/fused_data/CXR/pca/CXR_pca_labels.npy\n",
      "Epoch 1/5\n",
      "43/43 [==============================] - 1s 14ms/step - loss: 7.5747 - accuracy: 0.3750 - val_loss: 7.5247 - val_accuracy: 0.3750\n",
      "Epoch 2/5\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 4.9833 - accuracy: 0.5625 - val_loss: 5.3729 - val_accuracy: 0.5625\n",
      "Epoch 3/5\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 3.2625 - accuracy: 0.7734 - val_loss: 4.5168 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 3.0296 - accuracy: 0.7188 - val_loss: 4.3000 - val_accuracy: 0.6250\n",
      "Epoch 5/5\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 2.3225 - accuracy: 0.8047 - val_loss: 7.6824 - val_accuracy: 0.6250\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "[CXR] [pca] [fused_data] Fully_Connected Validation Results (Sample size = 20_CT_20_CXR):\n",
      "[CXR] [pca] [fused_data] Validation Accuracy: 0.625\n",
      "[CXR] [pca] [fused_data] Validation inference_time_train: 2.926630735397339\n",
      "[CXR] [pca] [fused_data] Validation inference_time_Validation: 0.08235049247741699\n",
      "Fully_Connected parameters: \n",
      " Fully_Connected\n",
      "[CXR] [pca] Validation Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0   0.500000  0.500000  0.500000         2\n",
      "           1   0.250000  0.500000  0.333333         2\n",
      "           2   0.000000  0.000000  0.000000         2\n",
      "           3   1.000000  1.000000  1.000000         2\n",
      "           4   1.000000  0.500000  0.666667         2\n",
      "           5   0.666667  1.000000  0.800000         2\n",
      "           6   1.000000  1.000000  1.000000         2\n",
      "           7   1.000000  0.500000  0.666667         2\n",
      "\n",
      "    accuracy                       0.625000        16\n",
      "   macro avg   0.677083  0.625000  0.620833        16\n",
      "weighted avg   0.677083  0.625000  0.620833        16\n",
      " \n",
      "\n",
      "‚úÖ Directory exists: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CXR\n",
      "[CXR]  [fused_data] [pca] Fully_Connected Validation results saved to /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CXR/CXR_pca_evaluation_results_20_CT_20_CXR.txt\n",
      "üìÅ Created directory: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CXR/CXR_pca_confusion_matrix\n",
      "[CXR] [pca] Fully_Connected fused_data Validation \n",
      "Confusion matrix saved to /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CXR/CXR_pca_confusion_matrix/CXR_pca_Fully_Connected_Validation_confusion_matrix_sample_size_20_CT_20_CXR.png\n",
      "‚úÖ Directory exists: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/saved_models/CXR\n",
      "Model training and evaluation complete. Model saved as 'CXR_fused_data_pca_Fully_Connected_model_sample_size_CXR.keras'\n",
      "üìÅ Created directory: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CXR/CXR_pca_training_plots\n",
      "[CXR] [pca] Fully_Connected fused_data 'accuracy' training plots saved to /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CXR/CXR_pca_training_plots/CXR_pca_Fully_Connected_accuracy_training_plots_sample_size_20_CT_20_CXR.png\n",
      "‚úÖ Directory exists: /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CXR/CXR_pca_training_plots\n",
      "[CXR] [pca] Fully_Connected fused_data 'loss' training plots saved to /home/masresha/dataset/resultfile/20_CT_20_CXR_resultfile/fused_data/evaluation_result/CXR/CXR_pca_training_plots/CXR_pca_Fully_Connected_loss_training_plots_sample_size_20_CT_20_CXR.png\n",
      "[done] All models evaluated and results saved.\n"
     ]
    }
   ],
   "source": [
    "for d_type in ['CT', 'CXR']:\n",
    "    print(\"üëâüëâüëâüëâ \", d_type, \" üëàüëàüëàüëà\")\n",
    "    feature_extraction_models = ['mi', 'rf', 'pca']\n",
    "    for feature_model in feature_extraction_models:\n",
    "        # Define parameters\n",
    "        parameters = {\n",
    "            # 'GradientBoosting': {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3, 'random_state': 42},\n",
    "            # 'RandomForest': {'n_estimators': 100, 'random_state': 42},\n",
    "            # 'XGBoost': {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3, 'random_state': 42},\n",
    "            # 'LightGBM': {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3, 'random_state': 42},\n",
    "            'CatBoost': {'iterations': 100, 'learning_rate': 0.1, 'depth': 3, 'random_state': 42, 'verbose': 0},\n",
    "            'MLP': {'hidden_layer_sizes': (100,), 'max_iter': 500, 'random_state': 42},\n",
    "            # 'SVM': {'kernel': 'rbf', 'C': 1, 'gamma': 'scale', 'probability': True},\n",
    "            # 'LogisticRegression': {'max_iter': 500, 'random_state': 42},  # Shorter key for consistency\n",
    "            # 'KNN': {'n_neighbors': 5}\n",
    "        }\n",
    "\n",
    "        # Define classifiers\n",
    "        classifiers = {}\n",
    "        # classifiers['GradientBoosting'] = GradientBoostingClassifier(**parameters['GradientBoosting'])\n",
    "        # classifiers['RandomForest'] = RandomForestClassifier(**parameters['RandomForest'])\n",
    "        # classifiers['XGBoost'] = XGBClassifier(**parameters['XGBoost'])\n",
    "        # classifiers['LightGBM'] = LGBMClassifier(**parameters['LightGBM'])\n",
    "        classifiers['CatBoost'] = CatBoostClassifier(**parameters['CatBoost'])\n",
    "        classifiers['MLP'] = MLPClassifier(**parameters['MLP'])\n",
    "        # classifiers['SVM'] = SVC(**parameters['SVM'])\n",
    "        # classifiers['LogisticRegression'] = LogisticRegression(**parameters['LogisticRegression'])\n",
    "        # classifiers['KNN'] = KNeighborsClassifier(**parameters['KNN'])\n",
    "        for training_type in ['fused_data', 'clinical_data_only','image_data_only']:\n",
    "\n",
    "            print(f\"‚è© Working on: {training_type} {feature_model} training\")\n",
    "   \n",
    "            # Load data\n",
    "            X, y = load_data(d_type, feature_model, training_type)\n",
    "            \n",
    "            # Step 1: Split into training (80%) and temporary set (20%)\n",
    "            X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "                X, y, test_size=0.2,random_state=42, stratify=y\n",
    "            )\n",
    "\n",
    "            # Step 2: Split the temporary set into testing (10%) and validation (10%)\n",
    "            X_test, X_val, y_test, y_val = train_test_split(\n",
    "                X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    "            )\n",
    "            \n",
    "            # # --> fused_data, clinical_data_only , image_data_only\n",
    "            # ## Train and evaluate classifiers Machine learning models\n",
    "            # for idx, (model_name, model) in enumerate(classifiers.items(), start=1):\n",
    "            #     print(f\"[{idx}/{len(classifiers)}] [{training_type}] [{d_type}] [{feature_model}] Training {model_name} with dataset size ({dataset})...\")\n",
    "            #     # Measure inference time\n",
    "            #     start_time = time.time()\n",
    "            #     model.fit(X_train, y_train)\n",
    "            #     end_time = time.time()\n",
    "            #     inference_time_train = end_time - start_time\n",
    "            #     # Evaluate on test set\n",
    "            #     start_time = time.time()\n",
    "            #     y_test_pred = model.predict(X_test)\n",
    "            #     end_time = time.time()\n",
    "            #     inference_time = end_time - start_time\n",
    "            #     export_evaluation_result(d_type, y_test, y_test_pred, model_name, feature_model, inference_time_train, inference_time,\"Test\", parameters[model_name], training_type)\n",
    "            #     # Evaluate on validation set\n",
    "            #     start_time = time.time()\n",
    "            #     y_val_pred = model.predict(X_val)\n",
    "            #     end_time = time.time()\n",
    "            #     inference_time = end_time - start_time\n",
    "            #     export_evaluation_result(d_type, y_val, y_val_pred, model_name, feature_model,inference_time_train,inference_time, \"Validation\", parameters[model_name], training_type)\n",
    "            #     # Save the model\n",
    "            #     save_model(d_type, model_name, model, feature_model, training_type)\n",
    "            #     print(f\"{training_type} training completed and result is saved\")\n",
    "\n",
    "            if training_type == 'clinical_data_only':\n",
    "                continue\n",
    "            ## --> fused_data and image_data_only\n",
    "            ## deep learning  using Fully connected modail working on feature extracted data\n",
    "            # Train and Evaluate with Deep Learning\n",
    "            model_name = 'Fully_Connected'\n",
    "            dl_model = build_deep_learning_model(input_dim=X_train.shape[1], output_dim=len(np.unique(y)))\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "            start_time = time.time()\n",
    "            history = dl_model.fit(X_train, y_train, validation_data = (X_val, y_val), epochs=5, batch_size=3,\n",
    "                                callbacks=[early_stopping], verbose=1)\n",
    "            end_time = time.time()\n",
    "            inference_time_train = end_time - start_time\n",
    "            \n",
    "            start_time = time.time()\n",
    "            dl_eval = dl_model.evaluate(X_test, y_test, verbose=0)\n",
    "            end_time = time.time()\n",
    "            inference_time = end_time - start_time\n",
    "            export_evaluation_result(d_type, y_val, dl_eval, model_name, feature_model,inference_time_train,inference_time, \"Eval_Test\", dl_eval, training_type)\n",
    "\n",
    "            start_time = time.time()\n",
    "            y_val_pred = dl_model.predict(X_val)\n",
    "            y_val_pred = np.argmax(y_val_pred, axis=1)\n",
    "            end_time = time.time()\n",
    "            inference_time = end_time - start_time\n",
    "            export_evaluation_result(d_type, y_val, y_val_pred, model_name, feature_model,inference_time_train,inference_time, \"Validation\", model_name, training_type)\n",
    "            \n",
    "            # Save the model\n",
    "            save_model(d_type, model_name, dl_model, feature_model, training_type, save_type='keras')\n",
    "            \n",
    "            acc = history.history['accuracy']\n",
    "            val_acc = history.history['val_accuracy']\n",
    "            loss = history.history['loss']\n",
    "            val_loss = history.history['val_loss']\n",
    "\n",
    "            epochs = range(1, len(acc) + 1)\n",
    "            # plot figures models\n",
    "            plot_graph(history, d_type, feature_model, model_name, training_type, dataset, 'accuracy')\n",
    "            plot_graph(history, d_type, feature_model, model_name, training_type, dataset, 'loss')\n",
    "            \n",
    "    ## --> image only  , withou fusing the data\n",
    "    for training_type in ['image_data_only']:\n",
    "        # Train CNN Models for Image Data\n",
    "        # Load data\n",
    "        X, y = load_data(d_type, feature_model, 'CNN')\n",
    "        X = np.expand_dims(X, axis=-1) # Add a single channel for grayscale\n",
    "        X = np.repeat(X, 3, axis=-1)  # Duplicate the single channel to simulate RGB\n",
    "        # Print the mapping\n",
    "        encoder = LabelEncoder()\n",
    "        y = encoder.fit_transform(y)  # Encodes labels as integers\n",
    "        label_mapping = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n",
    "        print(f\"Label Mapping: {label_mapping}\")\n",
    "        \n",
    "        # Step 1: Split into training (80%) and temporary set (20%)\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "            X, y, test_size=0.2,random_state=42, stratify=y\n",
    "        )\n",
    "\n",
    "        # Step 2: Split the temporary set into testing (10%) and validation (10%)\n",
    "        X_test, X_val, y_test, y_val = train_test_split(\n",
    "            X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    "        )\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "        height, width, channels = 224, 224, 3\n",
    "        \n",
    "        for cnn_model_name, cnn_model_builder in {\"ResNet50\": build_resnet50_model, \"EfficientNetB0\": build_efficientnetb0_model}.items():\n",
    "            cnn_model = cnn_model_builder(input_shape=(height, width, channels), output_dim=len(np.unique(y_train)))\n",
    "            history = cnn_model.fit(X_train, y_train,  validation_data = (X_val, y_val), epochs=5, batch_size=3,\n",
    "                                    callbacks=[early_stopping], verbose=1)\n",
    "            cnn_eval = cnn_model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "            # Save CNN Results\n",
    "            cnn_result_content = f\"{d_type} Image Data - {cnn_model_name}\\n\"\n",
    "            cnn_result_content += f\"Accuracy: {cnn_eval[1]}\\n\"\n",
    "            img_result_dir = os.path.join(result_data_directory, d_type, \"cnn_results\")\n",
    "            ensure_directory_exists(img_result_dir, True)\n",
    "            # save_results(img_result_dir, f\"{cnn_model_name}_results.txt\", cnn_result_content)\n",
    "            print(f\"{cnn_model_name}_results.txt\", cnn_result_content)\n",
    "            # cnn_model.save(os.path.join(img_result_dir, f\"{cnn_model_name}_model.h5\"))\n",
    "\n",
    "        print(\"Training and evaluation complete for all modalities and methods, including advanced deep learning models.\")\n",
    "\n",
    "            \n",
    "print(\"[done] All models evaluated and results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_train dtype: {X_train.dtype}\")\n",
    "print(f\"y_train dtype: {y_train.dtype}\")\n",
    "print(f\"X_val dtype: {X_val.dtype}\")\n",
    "print(f\"y_val dtype: {y_val.dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Unique y_train values: {np.unique(y_train)}\")\n",
    "print(f\"Unique y_val values: {np.unique(y_val)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume X has shape (1600, 224, 224) for grayscale images\n",
    "# Add a single channel for grayscale\n",
    "X = np.expand_dims(X, axis=-1)  # Shape becomes (1600, 224, 224, 1)\n",
    "\n",
    "# Duplicate the single channel to simulate RGB\n",
    "X_rgb = np.repeat(X, 3, axis=-1)  # Shape becomes (1600, 224, 224, 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
